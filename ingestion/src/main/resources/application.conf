# This is the main configuration file for our application, it provides overrides to the default values
# provided in the reference.conf of the modules from Akka
akka {
  actor {
    # Must be set like this to use Akka Cluster
    provider = cluster

    # Only for convenience in the quickstart, Java serialization should not be used for actual applications
    warn-about-java-serializer-usage = off


    //    serializers {
    //      java = "akka.serialization.JavaSerializer"
    //      kryo = "com.romix.akka.serialization.kryo.KryoSerializer"
    //    }
    //
    //    serialization-bindings {
    //      "utils.KryoSerializable" = kryo
    //    }

    //    kryo{
    //      type = "graph"
    //      idstrategy = "default"
    //      serializer-pool-size = 16
    //      buffer-size = 4096
    //      use-manifests = false
    //      implicit-registration-logging = false
    //      kryo-trace = false
    //    }

  }

  remote {
    maximum-payload-bytes = 100000000 bytes
    netty.tcp {
      message-frame-size = 100000000b
      send-buffer-size = 100000000b
      receive-buffer-size = 100000000b
      maximum-frame-size = 100000000b
    }
  }

  # Use slf4j (backed by logback) for logging, additional configuration
  # can be done in logback.xml
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  loglevel = INFO

  # For the sample, just bind to loopback and do not allow access from the network
  remote.netty.tcp.hostname = 127.0.0.1
  # the port is overridden by the logic in Main.scala
  remote.netty.tcp.port = 0

  cluster {
    # Seed nodes are a way to have a node join the cluster (or form a new cluster) from configuration.
    seed-nodes = [
      "akka.tcp://ClusterSystem@127.0.0.1:2551",
      "akka.tcp://ClusterSystem@127.0.0.1:2552",
      "akka.tcp://ClusterSystem@127.0.0.1:2553",
      "akka.tcp://ClusterSystem@127.0.0.1:2554"]

    # Only for convenience in the quickstart, auto-downing should not be used for actual applications.
    # Read more here: http://doc.akka.io/docs/akka/current/scala/cluster-usage.html#auto-downing-do-not-use-
    auto-down-unreachable-after = 10s

    # Needed when running many actor systems in the same JVM
    jmx.multi-mbeans-in-same-jvm = on
  }

  # use Cassandra to store both snapshots and the events of the persistent actors
  persistence {
    journal.plugin = "cassandra-journal"
    snapshot-store.plugin = "cassandra-snapshot-store"
  }

  # Run the pubsub mediator on all nodes, without any code starting it up
  extensions = ["akka.cluster.pubsub.DistributedPubSub",
    "com.romix.akka.serialization.kryo.KryoSerializationExtension$"]
}

# Configuration related to the app is in its own namespace
distributed-workers {
  # Each worker pings the master with this interval
  # to let it know that it is alive
  worker-registration-interval = 10s
  # If a worker hasn't gotten in touch in this long
  # it is removed from the set of workers
  consider-worker-dead-after = 60s
  # Must be shorter than all the source's work-timeout
  # recommended value is half of the minimum work-timeout
  clean-up-timeout = 10s

}


sources{

  copernicusOAH {

    description = "Copernicus Open Access Hub"

    base-url = "https://scihub.copernicus.eu/dhus/search?"
    fetching-frequency = 30s
    epoch = 6 //years
    # Retry starts after x seconds of the previous try
    retry-interval = 3s
    # Retry stops after x seconds without response
    retry-timeout = 5s
    # If a workload hasn't finished in this long it
    # is considered failed and is retried
    work-timeout = 20s
    start-delay = 30s
    page-size = 100
    credentials {
      username = "andrelopes"
      pwd = "andrelopez14"
    }

  }



}
